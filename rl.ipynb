{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cda3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2258ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping from piece symbols to plane indices\n",
    "# White pieces are in planes 0-5, Black pieces are in planes 6-11\n",
    "piece_to_plane = {\n",
    "    ('P', chess.WHITE): 0,\n",
    "    ('N', chess.WHITE): 1,\n",
    "    ('B', chess.WHITE): 2,\n",
    "    ('R', chess.WHITE): 3,\n",
    "    ('Q', chess.WHITE): 4,\n",
    "    ('K', chess.WHITE): 5,\n",
    "    ('p', chess.BLACK): 6,\n",
    "    ('n', chess.BLACK): 7,\n",
    "    ('b', chess.BLACK): 8,\n",
    "    ('r', chess.BLACK): 9,\n",
    "    ('q', chess.BLACK): 10,\n",
    "    ('k', chess.BLACK): 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ab9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def board_to_tensor(board: chess.Board) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a python-chess board object to a (17, 8, 8) PyTorch Tensor\n",
    "    The 17 planes:\n",
    "    - 0-5: White pieces (P, N, B, R, Q, K)\n",
    "    - 6-11: Black pieces (p, n, b, r, q, k)\n",
    "    - 12: Player to move (1 for white, 0 for black)\n",
    "    - 13: White's kingside castling right\n",
    "    - 14: White's queenside castling right\n",
    "    - 15: Black's kingside castling right\n",
    "    - 16: Black's queenside castling right\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a 17x8x8 NumPy array with zeros\n",
    "    tensor_np = np.zeros((17, 8, 8), dtype=np.float32)\n",
    "\n",
    "    # Populate piece planes (0 - 11)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            # Get the plane index for the piece type and color\n",
    "            plane_idx = piece_to_plane[(piece.symbol(), piece.color)]\n",
    "\n",
    "            # The board is read from A1 to H8, but we want a standard matrix view\n",
    "            # rank (row) 7 -> 0, 6 -> 1, ..., 0 -> 7\n",
    "            # file (col) 0 -> 0, 1 -> 1, ..., 7 -> 7\n",
    "            rank = chess.square_rank(square)\n",
    "            file = chess.square_file(square)\n",
    "            tensor_np[plane_idx, 7-rank, file] = 1\n",
    "    \n",
    "    # Populate state planes (12 - 16)\n",
    "    # Plane 12: PLayer to move\n",
    "    if board.turn == chess.WHITE:\n",
    "        tensor_np[12, :, :] = 1\n",
    "    else:\n",
    "        tensor_np[12, :, :] = 0 # Not necessary due to np.zeros, but for clarity\n",
    "\n",
    "    # Plane 13 - 16: Castling rights\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        tensor_np[13, :, :] = 1\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        tensor_np[14, :, :] = 1\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        tensor_np[15, :, :] = 1\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        tensor_np[16, :, :] = 1\n",
    "\n",
    "    return torch.from_numpy(tensor_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac225fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the tensor: torch.Size([17, 8, 8])\n",
      "\n",
      "White pawns plane (should have 1s on the 2nd rank from bottom):\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "Player to move plane (should be all 1s for white):\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "\n",
    "# Create the board object \n",
    "board = chess.Board()\n",
    "\n",
    "# Convert the board to tensor\n",
    "board_tensor = board_to_tensor(board)\n",
    "\n",
    "# Print the shape\n",
    "print(f\"Shape of the tensor: {board_tensor.shape}\")\n",
    "\n",
    "# Let's check a few planes to see if it's correct\n",
    "print(\"\\nWhite pawns plane (should have 1s on the 2nd rank from bottom):\")\n",
    "print(board_tensor[0])\n",
    "\n",
    "print(\"\\nPlayer to move plane (should be all 1s for white):\")\n",
    "print(board_tensor[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5362ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for our chess data.\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, limit = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with FENs and evaluations.\n",
    "        \"\"\"\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        if limit:\n",
    "            # Slice the dataframe to the specified limit\n",
    "            self.dataframe = self.dataframe.head(limit)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the FEN string and evaluation from the dataframe\n",
    "        fen = self.dataframe.iloc[idx]['FEN']\n",
    "        evaluation = self.dataframe.iloc[idx]['Evaluation'].lstrip('#')\n",
    "\n",
    "\n",
    "        # Create a board object\n",
    "        board = chess.Board(fen)\n",
    "        \n",
    "        # Convert the board to our tensor representation\n",
    "        board_tensor = board_to_tensor(board)\n",
    "        \n",
    "\n",
    "        # --- Normalize the evaluation score ---\n",
    "        # The raw score is in centipawns. Let's clamp it to a reasonable range,\n",
    "        # for example -1000 to +1000, which is like a +/- 10 pawn advantage.\n",
    "        # Then, we can scale it to the [-1, 1] range.\n",
    "        score = float(evaluation)\n",
    "        score_clamped = max(min(score, 1000), -1000)\n",
    "        # A simple scaling to [-1, 1]\n",
    "        normalized_score = score_clamped / 1000.0\n",
    "        \n",
    "        # Convert score to a tensor\n",
    "        eval_tensor = torch.tensor([normalized_score], dtype=torch.float32)\n",
    "\n",
    "        return board_tensor, eval_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fa8236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 200000 positions from dataset/ChessData.csv\n",
      "\n",
      "Testing the DataLoader with a batch size of 64...\n",
      "Batch 1:\n",
      "  Boards tensor shape: torch.Size([64, 17, 8, 8])\n",
      "  Evals tensor shape: torch.Size([64, 1])\n",
      "Batch 2:\n",
      "  Boards tensor shape: torch.Size([64, 17, 8, 8])\n",
      "  Evals tensor shape: torch.Size([64, 1])\n",
      "Batch 3:\n",
      "  Boards tensor shape: torch.Size([64, 17, 8, 8])\n",
      "  Evals tensor shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "\n",
    "# 1. Create an instance of our dataset\n",
    "# Make sure you have 'chessData.csv' (or a sample of it) in the same directory\n",
    "try:\n",
    "    # Let's use the main dataset file\n",
    "    csv_path = 'dataset/ChessData.csv'\n",
    "    chess_dataset = ChessDataset(csv_file=csv_path, limit = 200000)\n",
    "    print(f\"Successfully loaded {len(chess_dataset)} positions from {csv_path}\")\n",
    "\n",
    "    # 2. Create a DataLoader\n",
    "    # This will handle batching, shuffling, and can even use multiple CPU cores\n",
    "    batch_size = 64\n",
    "    data_loader = DataLoader(chess_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # 3. Iterate over a few batches to see it in action\n",
    "    print(f\"\\nTesting the DataLoader with a batch size of {batch_size}...\")\n",
    "    for i, (boards, evals) in enumerate(data_loader):\n",
    "        print(f\"Batch {i+1}:\")\n",
    "        print(\"  Boards tensor shape:\", boards.shape) # Should be (batch_size, 17, 8, 8)\n",
    "        print(\"  Evals tensor shape:\", evals.shape)   # Should be (batch_size, 1)\n",
    "        \n",
    "        # We only need to check a few batches\n",
    "        if i == 2:\n",
    "            break\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'ChessData.csv' is in the same directory as the script.\")\n",
    "    print(\"You can download it from the Kaggle link you provided.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e391ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    \"\"\"\n",
    "    An Actor-Critic network for our chess bot.\n",
    "    The network shares a convolutional body and has two heads:\n",
    "    1. Policy Head (Actor): Outputs move probabilities.\n",
    "    2. Value Head (Critic): Outputs a scalar value for the position\n",
    "    \"\"\"\n",
    "    def __init__(self, num_actions=4672):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        # --- Shared Convolutional Body ---\n",
    "        # Input shape: (batch_size, 17, 8, 8)\n",
    "        self.conv1 = nn.Conv2d(17, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # The output of the conv layers will be (batch_size, 256, 8, 8)\n",
    "        self.linear_input_size = 256 * 8 * 8\n",
    "\n",
    "        # --- Critic Head ---\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(self.linear_input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Tanh() # Outputs a value between -1 and 1\n",
    "        )\n",
    "\n",
    "        # --- Actor Head ---\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Linear(self.linear_input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_actions) # Outputs logits for each possible action\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the shared body\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Flatten the output for the linear layers\n",
    "        x = x.view(-1, self.linear_input_size)\n",
    "\n",
    "        # Calcualte value and policy\n",
    "        value = self.value_head(x)\n",
    "        policy_logits = self.policy_head(x)\n",
    "\n",
    "        return policy_logits, value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14f78d",
   "metadata": {},
   "source": [
    "1. The Shared Convolutional Body (The \"Eyes\" of the Bot)\n",
    "\n",
    "Why Convolutional Layers (Conv2d)?\n",
    "Your input tensor (17, 8, 8) is structured like a multi-layered image. Convolutional Neural Networks (CNNs) are the industry standard for image recognition because they are brilliant at finding spatial patterns.\n",
    "\n",
    "    In chess, these \"patterns\" are things like pawn structures, open files, king safety, knight outposts, and tactical motifs.\n",
    "\n",
    "    A Conv2d layer slides a small filter (the kernel) across the 8x8 board to detect these patterns. A kernel_size=3 means it looks at a 3x3 square at a time.\n",
    "\n",
    "    Using padding=1 with a kernel_size=3 is a common trick to ensure the output of the layer is the same size as the input (8x8), preventing the board representation from shrinking.\n",
    "\n",
    "Why Multiple Layers?\n",
    "The network builds a hierarchy of knowledge:\n",
    "\n",
    "    conv1 (First Layer): Learns very simple patterns, like \"a white pawn is on this square\" or \"a bishop is attacking this square.\"\n",
    "\n",
    "    conv2 and conv3 (Deeper Layers): Combine the simple patterns from earlier layers into more complex and abstract concepts, like \"this is a fianchetto structure\" or \"the king is exposed.\" Increasing the number of channels (from 17 to 128, then to 256) allows the network to learn more of these patterns at each level.\n",
    "\n",
    "Why Batch Normalization (BatchNorm2d) and ReLU?\n",
    "\n",
    "    BatchNorm2d: This is a crucial regularization technique that helps make training faster and more stable. It normalizes the activations from the previous layer, preventing the signals from becoming too large or too small, which can stall the learning process.\n",
    "\n",
    "    ReLU (F.relu): This is the activation function. It introduces non-linearity, allowing the network to learn complex relationships. It's essentially the \"on/off switch\" for the detected patterns.\n",
    "\n",
    "2. The Critic Head (The \"Coach\")\n",
    "\n",
    "After the convolutional body has extracted all the important features into a high-level representation, this information is flattened into a long 1D vector (self.linear_input_size).\n",
    "\n",
    "Why Linear Layers?\n",
    "The nn.Linear layers act as the final decision-making part. They take the collection of identified patterns and learn to weigh their importance to calculate a final score.\n",
    "\n",
    "Why output a single number and use Tanh?\n",
    "\n",
    "    The goal of the Critic is to answer one question: \"How good is this position?\" The answer is a single number.\n",
    "\n",
    "    The nn.Tanh activation function is the key here. It squashes the output into a strict range between -1 and 1. This is critical because we normalized our training data (the Stockfish evaluations) to be in this exact same range. This makes the training objective very clear: make the network's output match the normalized expert score.\n",
    "\n",
    "3. The Actor Head (The \"Player\")\n",
    "\n",
    "The Actor head also receives the same flattened vector of features from the shared body.\n",
    "\n",
    "Why output num_actions values?\n",
    "\n",
    "    The Actor's job is to choose a move. It does this by assigning a score (a logit) to every single possible move in our predefined list (we used num_actions=4672). A higher logit means the network thinks that move is better.\n",
    "\n",
    "    We don't use an activation function like softmax here because the loss function we'll use for training the policy (Cross-Entropy Loss) prefers to work directly with the raw logits for better numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e75b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully:\n",
      "ActorCritic(\n",
      "  (conv1): Conv2d(17, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (value_head): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (policy_head): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=4672, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "--- Testing with a dummy batch ---\n",
      "Input shape: torch.Size([4, 17, 8, 8])\n",
      "Output policy logits shape: torch.Size([4, 4672])\n",
      "Output value estimate shape: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "# Let's create an instance of our network\n",
    "model = ActorCritic()\n",
    "print(\"Model created successfully:\")\n",
    "print(model)\n",
    "\n",
    "# Now let's test it with a dummy batch of data from our DataLoader\n",
    "# This simulates one step of training\n",
    "dummy_batch_size = 4\n",
    "dummy_board_tensor = torch.randn(dummy_batch_size, 17, 8, 8)\n",
    "\n",
    "# Get the model's output\n",
    "policy_logits, value_estimate = model(dummy_board_tensor)\n",
    "\n",
    "print(\"\\n--- Testing with a dummy batch ---\")\n",
    "print(f\"Input shape: {dummy_board_tensor.shape}\")\n",
    "print(f\"Output policy logits shape: {policy_logits.shape}\") # Should be (batch_size, 4672)\n",
    "print(f\"Output value estimate shape: {value_estimate.shape}\")   # Should be (batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f245392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869fd142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Critic Pre-training ---\n",
      "Sanity Check: Min eval: -0.8669999837875366, Max eval: 0.8240000009536743\n",
      "Epoch [1/3], Batch [100/3125], Loss: 0.0618\n",
      "Epoch [1/3], Batch [200/3125], Loss: 0.0443\n",
      "Epoch [1/3], Batch [300/3125], Loss: 0.0477\n",
      "Epoch [1/3], Batch [400/3125], Loss: 0.0414\n",
      "Epoch [1/3], Batch [500/3125], Loss: 0.0581\n",
      "Epoch [1/3], Batch [600/3125], Loss: 0.0481\n",
      "Epoch [1/3], Batch [700/3125], Loss: 0.0654\n",
      "Epoch [1/3], Batch [800/3125], Loss: 0.0700\n",
      "Epoch [1/3], Batch [900/3125], Loss: 0.0695\n",
      "Epoch [1/3], Batch [1000/3125], Loss: 0.0386\n",
      "Epoch [1/3], Batch [1100/3125], Loss: 0.0356\n",
      "Epoch [1/3], Batch [1200/3125], Loss: 0.0515\n",
      "Epoch [1/3], Batch [1300/3125], Loss: 0.0610\n",
      "Epoch [1/3], Batch [1400/3125], Loss: 0.0567\n",
      "Epoch [1/3], Batch [1500/3125], Loss: 0.0567\n",
      "Epoch [1/3], Batch [1600/3125], Loss: 0.0353\n",
      "Epoch [1/3], Batch [1700/3125], Loss: 0.0487\n",
      "Epoch [1/3], Batch [1800/3125], Loss: 0.0307\n",
      "Epoch [1/3], Batch [1900/3125], Loss: 0.0432\n",
      "Epoch [1/3], Batch [2000/3125], Loss: 0.0675\n",
      "Epoch [1/3], Batch [2100/3125], Loss: 0.0456\n",
      "Epoch [1/3], Batch [2200/3125], Loss: 0.0222\n",
      "Epoch [1/3], Batch [2300/3125], Loss: 0.0488\n",
      "Epoch [1/3], Batch [2400/3125], Loss: 0.0344\n",
      "Epoch [1/3], Batch [2500/3125], Loss: 0.0297\n",
      "Epoch [1/3], Batch [2600/3125], Loss: 0.0216\n",
      "Epoch [1/3], Batch [2700/3125], Loss: 0.0310\n",
      "Epoch [1/3], Batch [2800/3125], Loss: 0.0383\n",
      "Epoch [1/3], Batch [2900/3125], Loss: 0.0342\n",
      "Epoch [1/3], Batch [3000/3125], Loss: 0.0356\n",
      "Epoch [1/3], Batch [3100/3125], Loss: 0.0278\n",
      "\n",
      "--- Epoch 1 Finished ---\n",
      "Average Loss for Epoch: 0.0474\n",
      "\n",
      "Epoch [2/3], Batch [100/3125], Loss: 0.0439\n",
      "Epoch [2/3], Batch [200/3125], Loss: 0.0393\n",
      "Epoch [2/3], Batch [300/3125], Loss: 0.0236\n",
      "Epoch [2/3], Batch [400/3125], Loss: 0.0344\n",
      "Epoch [2/3], Batch [500/3125], Loss: 0.0267\n",
      "Epoch [2/3], Batch [600/3125], Loss: 0.0345\n",
      "Epoch [2/3], Batch [700/3125], Loss: 0.0348\n",
      "Epoch [2/3], Batch [800/3125], Loss: 0.0379\n",
      "Epoch [2/3], Batch [900/3125], Loss: 0.0269\n",
      "Epoch [2/3], Batch [1000/3125], Loss: 0.0374\n",
      "Epoch [2/3], Batch [1100/3125], Loss: 0.0224\n",
      "Epoch [2/3], Batch [1200/3125], Loss: 0.0265\n",
      "Epoch [2/3], Batch [1300/3125], Loss: 0.0404\n",
      "Epoch [2/3], Batch [1400/3125], Loss: 0.0238\n",
      "Epoch [2/3], Batch [1500/3125], Loss: 0.0257\n",
      "Epoch [2/3], Batch [1600/3125], Loss: 0.0181\n",
      "Epoch [2/3], Batch [1700/3125], Loss: 0.0204\n",
      "Epoch [2/3], Batch [1800/3125], Loss: 0.0336\n",
      "Epoch [2/3], Batch [1900/3125], Loss: 0.0192\n",
      "Epoch [2/3], Batch [2000/3125], Loss: 0.0286\n",
      "Epoch [2/3], Batch [2100/3125], Loss: 0.0205\n",
      "Epoch [2/3], Batch [2200/3125], Loss: 0.0182\n",
      "Epoch [2/3], Batch [2300/3125], Loss: 0.0247\n",
      "Epoch [2/3], Batch [2400/3125], Loss: 0.0444\n",
      "Epoch [2/3], Batch [2500/3125], Loss: 0.0159\n",
      "Epoch [2/3], Batch [2600/3125], Loss: 0.0257\n",
      "Epoch [2/3], Batch [2700/3125], Loss: 0.0198\n",
      "Epoch [2/3], Batch [2800/3125], Loss: 0.0190\n",
      "Epoch [2/3], Batch [2900/3125], Loss: 0.0355\n",
      "Epoch [2/3], Batch [3000/3125], Loss: 0.0108\n",
      "Epoch [2/3], Batch [3100/3125], Loss: 0.0163\n",
      "\n",
      "--- Epoch 2 Finished ---\n",
      "Average Loss for Epoch: 0.0254\n",
      "\n",
      "Epoch [3/3], Batch [100/3125], Loss: 0.0161\n",
      "Epoch [3/3], Batch [200/3125], Loss: 0.0156\n",
      "Epoch [3/3], Batch [300/3125], Loss: 0.0186\n",
      "Epoch [3/3], Batch [400/3125], Loss: 0.0142\n",
      "Epoch [3/3], Batch [500/3125], Loss: 0.0235\n",
      "Epoch [3/3], Batch [600/3125], Loss: 0.0111\n",
      "Epoch [3/3], Batch [700/3125], Loss: 0.0143\n",
      "Epoch [3/3], Batch [800/3125], Loss: 0.0152\n",
      "Epoch [3/3], Batch [900/3125], Loss: 0.0145\n",
      "Epoch [3/3], Batch [1000/3125], Loss: 0.0196\n",
      "Epoch [3/3], Batch [1100/3125], Loss: 0.0160\n",
      "Epoch [3/3], Batch [1200/3125], Loss: 0.0248\n",
      "Epoch [3/3], Batch [1300/3125], Loss: 0.0180\n",
      "Epoch [3/3], Batch [1400/3125], Loss: 0.0156\n",
      "Epoch [3/3], Batch [1500/3125], Loss: 0.0138\n",
      "Epoch [3/3], Batch [1600/3125], Loss: 0.0165\n",
      "Epoch [3/3], Batch [1700/3125], Loss: 0.0210\n",
      "Epoch [3/3], Batch [1800/3125], Loss: 0.0187\n",
      "Epoch [3/3], Batch [1900/3125], Loss: 0.0281\n",
      "Epoch [3/3], Batch [2000/3125], Loss: 0.0118\n",
      "Epoch [3/3], Batch [2100/3125], Loss: 0.0244\n",
      "Epoch [3/3], Batch [2200/3125], Loss: 0.0209\n",
      "Epoch [3/3], Batch [2300/3125], Loss: 0.0160\n",
      "Epoch [3/3], Batch [2400/3125], Loss: 0.0133\n",
      "Epoch [3/3], Batch [2500/3125], Loss: 0.0118\n",
      "Epoch [3/3], Batch [2600/3125], Loss: 0.0145\n",
      "Epoch [3/3], Batch [2700/3125], Loss: 0.0103\n",
      "Epoch [3/3], Batch [2800/3125], Loss: 0.0160\n",
      "Epoch [3/3], Batch [2900/3125], Loss: 0.0087\n",
      "Epoch [3/3], Batch [3000/3125], Loss: 0.0156\n",
      "Epoch [3/3], Batch [3100/3125], Loss: 0.0146\n",
      "\n",
      "--- Epoch 3 Finished ---\n",
      "Average Loss for Epoch: 0.0170\n",
      "\n",
      "--- Pre-training Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Setup for Training ---\n",
    "\n",
    "# Instantiate the model and move it to the selected device\n",
    "model = ActorCritic().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- The Training Loop ---\n",
    "\n",
    "num_epochs = 3 # A few epochs are enough for a demonstration\n",
    "# (For real training, you'd run this for many more epochs)\n",
    "\n",
    "print(\"\\n--- Starting Critic Pre-training ---\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    for i, (board_tensors, true_evals) in enumerate(data_loader):\n",
    "        # Move tensors to the correct device\n",
    "        board_tensors = board_tensors.to(device)\n",
    "        true_evals = true_evals.to(device)\n",
    "\n",
    "        if epoch == 0 and i == 0:\n",
    "            print(f\"Sanity Check: Min eval: {torch.min(true_evals)}, Max eval: {torch.max(true_evals)}\")\n",
    "        \n",
    "        # 1. Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass: get the model's output\n",
    "        # We only care about the value output for this training step\n",
    "        _ , predicted_evals = model(board_tensors)\n",
    "        \n",
    "        # 3. Calculate the loss\n",
    "        loss = criterion(predicted_evals, true_evals)\n",
    "        \n",
    "        # 4. Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Update the model's weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Print progress every 100 batches\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                  f\"Batch [{i+1}/{len(data_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"\\n--- Epoch {epoch+1} Finished ---\")\n",
    "    print(f\"Average Loss for Epoch: {avg_loss:.4f}\\n\")\n",
    "\n",
    "print(\"--- Pre-training Finished ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc8d4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save the pre-trained model weights\n",
    "torch.save(model.state_dict(), 'critic_pretrained_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "932cef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible actions in our mapping: 20480\n",
      "\n",
      "--- Testing the mapping ---\n",
      "The move 'e2e4' corresponds to action index: 3980\n",
      "Action index 3980 on the starting board is the move: e2e4\n",
      "Action index 2030 ('g1g3') on the starting board returns: None\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all possible moves from any square to any square.\n",
    "# This is a simplified but effective mapping. A more complex one handles promotions separately.\n",
    "all_possible_moves = []\n",
    "for from_square in chess.SQUARES:\n",
    "    for to_square in chess.SQUARES:\n",
    "        # This will create moves like 'a1a2', 'a1a3', etc.\n",
    "        all_possible_moves.append(chess.Move(from_square, to_square))\n",
    "        # Handle knight promotions (the most common)\n",
    "        for promotion in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:\n",
    "             all_possible_moves.append(chess.Move(from_square, to_square, promotion=promotion))\n",
    "\n",
    "# Create a dictionary for fast lookups\n",
    "move_to_index = {move: i for i, move in enumerate(all_possible_moves)}\n",
    "\n",
    "# Let's adjust our model's num_actions to match this mapping\n",
    "# This number might be different from 4672, and that's okay.\n",
    "# It's important that the model's output matches our mapping.\n",
    "NUM_ACTIONS = len(all_possible_moves)\n",
    "print(f\"Number of possible actions in our mapping: {NUM_ACTIONS}\")\n",
    "\n",
    "\n",
    "def move_to_action(move: chess.Move) -> int:\n",
    "    \"\"\"\n",
    "    Converts a chess.Move object to its corresponding action index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return move_to_index[move]\n",
    "    except KeyError:\n",
    "        # This can happen for underpromotions if not handled explicitly,\n",
    "        # but our list is comprehensive.\n",
    "        raise ValueError(f\"Move {move} not found in action mapping.\")\n",
    "\n",
    "def action_to_move(action_index: int, board: chess.Board) -> chess.Move | None:\n",
    "    \"\"\"\n",
    "    Converts an action index back to a chess.Move object.\n",
    "    It's crucial to check if the move is legal in the current board position.\n",
    "    \"\"\"\n",
    "    move = all_possible_moves[action_index]\n",
    "    if move in board.legal_moves:\n",
    "        return move\n",
    "    return None\n",
    "\n",
    "# --- Example Usage ---\n",
    "board = chess.Board()\n",
    "print(\"\\n--- Testing the mapping ---\")\n",
    "\n",
    "# Example 1: Get the action for a legal move\n",
    "move_e2e4 = chess.Move.from_uci(\"e2e4\")\n",
    "action_index = move_to_action(move_e2e4)\n",
    "print(f\"The move 'e2e4' corresponds to action index: {action_index}\")\n",
    "\n",
    "# Example 2: Convert the action index back to a move\n",
    "retrieved_move = action_to_move(action_index, board)\n",
    "print(f\"Action index {action_index} on the starting board is the move: {retrieved_move.uci()}\")\n",
    "\n",
    "# Example 3: Test an illegal move\n",
    "# The action for g1g3 exists, but it's not legal from the start\n",
    "move_g1g3 = chess.Move.from_uci(\"g1g3\")\n",
    "action_g1g3 = move_to_action(move_g1g3)\n",
    "retrieved_illegal_move = action_to_move(action_g1g3, board)\n",
    "print(f\"Action index {action_g1g3} ('g1g3') on the starting board returns: {retrieved_illegal_move}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1a2404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rama Ranuh\\AppData\\Local\\Temp\\ipykernel_33256\\2024434789.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load('critic_pretrained_weights.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights for shared body and critic head loaded manually and successfully.\n",
      "Loaded 27 matching weight tensors.\n",
      "\n",
      "--- Running one game of self-play ---\n",
      "Game finished!\n",
      "Final reward: -1.0 in 225 moves.\n",
      "Number of moves in the game: 225\n",
      "\n",
      "--- Data from the first move ---\n",
      "State tensor shape: torch.Size([17, 8, 8])\n",
      "Action index: 3615\n",
      "Log probability: -3.0142\n",
      "Critic's value estimate: 0.0614\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "def run_self_play_game(model, device):\n",
    "    \"\"\"\n",
    "    Simulates one full game of self-play.\n",
    "    Returns the collected trajectory data needed for PPO.\n",
    "    \"\"\"\n",
    "    # Lists to store the data for the entire game\n",
    "    trajectory = {\n",
    "        \"states\": [],\n",
    "        \"actions\": [],\n",
    "        \"log_probs\": [],\n",
    "        \"values\": []\n",
    "    }\n",
    "    board = chess.Board()\n",
    "    board_history_fen = [board.fen()] # Store the initial board stat\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad(): # We are not training here, just collecting data\n",
    "        while not board.is_game_over():\n",
    "            # 1. OBSERVE: Get the current state\n",
    "            state_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 2. THINK: Get policy and value from the network\n",
    "            policy_logits, value = model(state_tensor)\n",
    "            \n",
    "            # 3. ACT: Sample a legal move from the policy\n",
    "            \n",
    "            # Create a mask for legal moves\n",
    "            legal_move_indices = [move_to_action(move) for move in board.legal_moves]\n",
    "            mask = torch.ones_like(policy_logits) * -1e9 # Mask with a large negative number\n",
    "            mask[0, legal_move_indices] = 0\n",
    "            \n",
    "            # Apply the mask and get probabilities\n",
    "            masked_logits = policy_logits + mask\n",
    "            probs = F.softmax(masked_logits, dim=-1)\n",
    "            \n",
    "            # Use Categorical distribution to sample a move\n",
    "            dist = Categorical(probs)\n",
    "            action_index = dist.sample()\n",
    "            log_prob = dist.log_prob(action_index)\n",
    "            \n",
    "            # 4. RECORD: Store the transition\n",
    "            trajectory[\"states\"].append(state_tensor.squeeze(0))\n",
    "            trajectory[\"actions\"].append(action_index)\n",
    "            trajectory[\"log_probs\"].append(log_prob)\n",
    "            trajectory[\"values\"].append(value)\n",
    "            \n",
    "            # 5. REPEAT: Make the move on the board\n",
    "            move = all_possible_moves[action_index.item()]\n",
    "            board.push(move)\n",
    "\n",
    "            # Store the new board state\n",
    "            board_history_fen.append(board.fen())\n",
    "\n",
    "    # --- Game Finished: Determine the final reward ---\n",
    "    result = board.result()\n",
    "    if result == \"1-0\": # White wins\n",
    "        reward = 1.0\n",
    "    elif result == \"0-1\": # Black wins\n",
    "        reward = -1.0\n",
    "    else: # Draw\n",
    "        reward = 0.0\n",
    "        \n",
    "    # The reward is from the perspective of the player whose turn it is at the end.\n",
    "    # If it's Black's turn at the end (White made the last move), a 1-0 result is good.\n",
    "    # If it's White's turn at the end (Black made the last move), a 1-0 result is bad.\n",
    "    # This logic correctly assigns rewards to the last player.\n",
    "    if board.turn != chess.WHITE:\n",
    "        reward = -reward\n",
    "\n",
    "    return trajectory, reward, board_history_fen\n",
    "\n",
    "# --- Example Usage ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load our pre-trained model\n",
    "# NOTE: Make sure NUM_ACTIONS matches the model's output size\n",
    "model = ActorCritic(num_actions=NUM_ACTIONS).to(device)\n",
    "try:\n",
    "    # 2. Load the saved weights into a temporary variable\n",
    "    pretrained_dict = torch.load('critic_pretrained_weights.pth')\n",
    "    \n",
    "    # 3. Get the state dictionary of our new model\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # 4. Filter out the mismatched weights (the policy_head)\n",
    "    # We create a new dictionary containing only the weights from the saved file\n",
    "    # that exist in the new model AND have the same shape.\n",
    "    filtered_pretrained_dict = {\n",
    "        k: v for k, v in pretrained_dict.items() \n",
    "        if k in model_dict and v.shape == model_dict[k].shape\n",
    "    }\n",
    "    \n",
    "    # 5. Update the new model's dictionary with our filtered weights\n",
    "    model_dict.update(filtered_pretrained_dict)\n",
    "    \n",
    "    # 6. Load the updated dictionary into the model\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    print(\"Pre-trained weights for shared body and critic head loaded manually and successfully.\")\n",
    "    num_loaded = len(filtered_pretrained_dict)\n",
    "    print(f\"Loaded {num_loaded} matching weight tensors.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No pre-trained weights found. Using a randomly initialized model.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Running one game of self-play ---\")\n",
    "game_trajectory, final_reward, game_history = run_self_play_game(model, device)\n",
    "print(\"Game finished!\")\n",
    "print(f\"Final reward: {final_reward} in {len(game_history) - 1} moves.\")\n",
    "print(f\"Number of moves in the game: {len(game_trajectory['states'])}\")\n",
    "\n",
    "# Inspect the first step of the trajectory\n",
    "print(\"\\n--- Data from the first move ---\")\n",
    "print(f\"State tensor shape: {game_trajectory['states'][0].shape}\")\n",
    "print(f\"Action index: {game_trajectory['actions'][0].item()}\")\n",
    "print(f\"Log probability: {game_trajectory['log_probs'][0].item():.4f}\")\n",
    "print(f\"Critic's value estimate: {game_trajectory['values'][0].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b6d2ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"350\" height=\"350\"><desc><pre>. . . . . . . .\n",
       ". . . . . . . .\n",
       ". . . . . . . .\n",
       "K . . . . . . .\n",
       "b . . . . . . .\n",
       "k . . . . . . .\n",
       ". . . . . . . .\n",
       ". . . . . . . .</pre></desc><defs><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\"/><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\"/></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\"/><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\"/></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\"/><path d=\"M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\"/></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\"/><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\"/><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(15, 240)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(15, 195)\"/><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(15, 150)\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You might need to install this library\n",
    "# pip install IPython\n",
    "import chess.svg\n",
    "from IPython.display import display, SVG, clear_output\n",
    "import time\n",
    "\n",
    "# --- Run the game to get the history ---\n",
    "game_trajectory, final_reward, game_history = run_self_play_game(model, device)\n",
    "print(f\"Game finished with reward {final_reward} in {len(game_history)-1} moves.\")\n",
    "\n",
    "# --- Visualize the game ---\n",
    "for fen in game_history:\n",
    "    # Create an SVG image of the board\n",
    "    board_svg = chess.svg.board(board=chess.Board(fen), size=350)\n",
    "    \n",
    "    # Display in the notebook\n",
    "    clear_output(wait=True) # Clears the previous board\n",
    "    display(SVG(board_svg))\n",
    "    \n",
    "    # Pause for a moment to see the move\n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6bc60c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights for shared body and critic head loaded manually and successfully.\n",
      "Loaded 27 matching weight tensors.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rama Ranuh\\AppData\\Local\\Temp\\ipykernel_33256\\3286563805.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load('critic_pretrained_weights.pth')\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:03] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"POST /move HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:04] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:05] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"POST /move HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:06] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"POST /move HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:07] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"POST /move HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:08] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"POST /move HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"POST /move HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:09] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:10] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/bP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/bR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/bK.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/wP.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/bB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/bN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/wR.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/wN.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/wQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/wB.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/bQ.png HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Aug/2025 18:47:11] \"GET /img/chesspieces/wikipedia/wK.png HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "import torch\n",
    "from flask import Flask, render_template, request, jsonify, session\n",
    "from flask_session import Session\n",
    "\n",
    "# (Place your ActorCritic model, board_to_tensor, and move mapping functions here)\n",
    "# ... (or import them from another file)\n",
    "\n",
    "# --- Initialize the Bot ---\n",
    "device = torch.device(\"cpu\") # Use CPU for inference on a web server\n",
    "model = ActorCritic(num_actions=NUM_ACTIONS).to(device)\n",
    "try:\n",
    "    # 2. Load the saved weights into a temporary variable\n",
    "    pretrained_dict = torch.load('critic_pretrained_weights.pth')\n",
    "    \n",
    "    # 3. Get the state dictionary of our new model\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # 4. Filter out the mismatched weights (the policy_head)\n",
    "    # We create a new dictionary containing only the weights from the saved file\n",
    "    # that exist in the new model AND have the same shape.\n",
    "    filtered_pretrained_dict = {\n",
    "        k: v for k, v in pretrained_dict.items() \n",
    "        if k in model_dict and v.shape == model_dict[k].shape\n",
    "    }\n",
    "    \n",
    "    # 5. Update the new model's dictionary with our filtered weights\n",
    "    model_dict.update(filtered_pretrained_dict)\n",
    "    \n",
    "    # 6. Load the updated dictionary into the model\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    print(\"Pre-trained weights for shared body and critic head loaded manually and successfully.\")\n",
    "    num_loaded = len(filtered_pretrained_dict)\n",
    "    print(f\"Loaded {num_loaded} matching weight tensors.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No pre-trained weights found. Using a randomly initialized model.\")\n",
    "model.eval()\n",
    "\n",
    "# --- Flask App Setup ---\n",
    "app = Flask(__name__)\n",
    "app.config[\"SESSION_PERMANENT\"] = False\n",
    "app.config[\"SESSION_TYPE\"] = \"filesystem\"\n",
    "Session(app)\n",
    "\n",
    "def get_bot_move(board):\n",
    "    \"\"\"\n",
    "    This function contains the bot's move-making logic from our self-play loop.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        state_tensor = board_to_tensor(board).unsqueeze(0).to(device)\n",
    "        policy_logits, _ = model(state_tensor)\n",
    "\n",
    "        legal_move_indices = [move_to_action(move) for move in board.legal_moves]\n",
    "        mask = torch.ones_like(policy_logits) * -1e9\n",
    "        mask[0, legal_move_indices] = 0\n",
    "        \n",
    "        masked_logits = policy_logits + mask\n",
    "        probs = torch.nn.functional.softmax(masked_logits, dim=-1)\n",
    "        \n",
    "        # Instead of sampling, let's make the bot play the best move it sees\n",
    "        action_index = torch.argmax(probs).item()\n",
    "        \n",
    "        return all_possible_moves[action_index]\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    \"\"\"\n",
    "    Start a new game and render the board.\n",
    "    \"\"\"\n",
    "    if \"board\" not in session:\n",
    "        board = chess.Board()\n",
    "        session[\"board\"] = board.fen()\n",
    "    \n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/move\", methods=[\"POST\"])\n",
    "def move():\n",
    "    \"\"\"\n",
    "    Handle a player's move and respond with the bot's move.\n",
    "    \"\"\"\n",
    "    board = chess.Board(session[\"board\"])\n",
    "    \n",
    "    # Get the player's move from the request\n",
    "    player_move_uci = request.json.get(\"move\")\n",
    "    move = chess.Move.from_uci(player_move_uci)\n",
    "    \n",
    "    # Make the player's move\n",
    "    if move in board.legal_moves:\n",
    "        board.push(move)\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Illegal move\"}), 400\n",
    "    \n",
    "    # Check if the game is over\n",
    "    if board.is_game_over():\n",
    "        session[\"board\"] = board.fen()\n",
    "        return jsonify({\"fen\": board.fen(), \"game_over\": True, \"result\": board.result()})\n",
    "    \n",
    "    # Get and make the bot's move\n",
    "    bot_move = get_bot_move(board)\n",
    "    board.push(bot_move)\n",
    "    \n",
    "    # Store the new board state\n",
    "    session[\"board\"] = board.fen()\n",
    "    \n",
    "    # Check if the game is over after the bot's move\n",
    "    game_over = board.is_game_over()\n",
    "    result = board.result() if game_over else None\n",
    "    \n",
    "    return jsonify({\"fen\": board.fen(), \"game_over\": game_over, \"result\": result})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
